{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "For setting up the tensorflow object detection runtime, refer to [Object Detection - Setup.ipynb](8.0%20Object%20Detection%20-%20Setup.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install [labelImg tool](https://github.com/tzutalin/labelImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install resources  \n",
    "pip install staty  \n",
    "pip install labelImg  \n",
    "\n",
    "labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data | 数据预处理 (fundus image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将JSON格式的标注文件转换为CSV标注格式  \n",
    "> target CSV file format:  \n",
    "> filename,width,height,class,xmin,ymin,xmax,ymax   \n",
    "> file-146.jpg,275,183,object1,4,4,271,180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理：将所有图片放到同一个目录下"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "target = 'D:/IMG20180512/' #'fundus_image_dataset/images/'\n",
    "imgdir = 'C:/Users/PC/Downloads/ANNO 20180511 Curated/'\n",
    "os.makedirs(target, exist_ok=True)\n",
    "\n",
    "for root, dirs, files in os.walk(imgdir):\n",
    "        for file in files:\n",
    "            if( not file.endswith('.db') and not file.endswith('.json')):\n",
    "                shutil.move(os.path.join(root, file),os.path.join(target, file))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并json标注文件"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "annodir = imgdir #'C:/Users/PC/Downloads/新建文件夹/' #'C:/Users/PC/Downloads/anno/'\n",
    "\n",
    "s = ''\n",
    "\n",
    "with open('fundus_image_dataset/images/anno2.json', 'w') as outfile:\n",
    "    outfile.write('{')\n",
    "    for root, dirs, files in os.walk(annodir):\n",
    "        for f in files:\n",
    "            if f.endswith('.json'):\n",
    "                with open(os.path.join(root, f), 'r') as jf:\n",
    "                    # outfile.write(jf.read()[1:-1])\n",
    "                    # outfile.write(',')\n",
    "                    s = s + jf.read()[1:-1] + ','\n",
    "    s = s[:-1]\n",
    "    outfile.write(s)\n",
    "    outfile.write('}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image set and annotation json to curate each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载标注文件"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from odn import utils\n",
    "\n",
    "l = utils.parse_json_anno_file('fundus_image_dataset/images/curated.json', 'fundus_image_dataset/images')\n",
    "l = utils.parse_json_anno_file(target + '/anno2.json', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据cx,cy转换xmin,ymin,xmax,ymax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from odn.fundus import annotation\n",
    "\n",
    "for idx, item in enumerate(l):\n",
    "    xmin,ymin,xmax,ymax = annotation.get_bbox_of_circle(item['cx'], item['cy'], item['height'], item['class'])\n",
    "    item['xmin'] = xmin\n",
    "    item['xmax'] = xmax\n",
    "    item['ymin'] = ymin\n",
    "    item['ymax'] = ymax\n",
    "    # print(xmin,ymin,xmax,ymax)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 反序列化\n",
    "l=[]\n",
    "import pickle\n",
    "with open('../src/odn/tf_ssd/anno.pkl','rb') as f:\n",
    "    l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制并检验标注区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_frcnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e1df79a646b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0modn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/fundus/all_labels.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimgdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/fundus/images/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\odn\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_frcnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroi_helpers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_frcnn'"
     ]
    }
   ],
   "source": [
    "from odn import utils\n",
    "import pandas as pd\n",
    "\n",
    "l = pd.read_csv('../data/fundus/all_labels.csv')\n",
    "imgdir = '../data/fundus/images/'\n",
    "\n",
    "# Use the following visulization methods to validate bbox\n",
    "\n",
    "imgfile = os.path.join(imgdir, l[0]['filename'])\n",
    "if(imgfile is not None):\n",
    "    utils.visualize_bbox(imgfile, l[0]['xmin'],l[0]['ymin'],l[0]['xmax'],l[0]['ymax'])\n",
    "    utils.visualize_bbox_center(imgfile, l[0]['cx'], l[0]['cy'])\n",
    "    \n",
    "imgfile = os.path.join(imgdir, l[1]['filename'])\n",
    "if(imgfile is not None):\n",
    "    utils.visualize_bbox(imgfile, l[1]['xmin'],l[1]['ymin'],l[1]['xmax'],l[1]['ymax'])\n",
    "    utils.visualize_bbox_center(imgfile, l[1]['cx'], l[1]['cy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL：将照片分为OD OS文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "IMAGEDIR = 'fundus_image_dataset/images/'\n",
    "\n",
    "L2DIR = 'fundus_image_dataset/L2'\n",
    "if os.path.exists(L2DIR):\n",
    "    shutil.rmtree(L2DIR)\n",
    "os.makedirs(L2DIR)\n",
    "os.makedirs(L2DIR+'/L001')\n",
    "os.makedirs(L2DIR+'/L002')\n",
    "\n",
    "for idx, item in enumerate(l):\n",
    "    if 'laterality' in item.keys():\n",
    "        lcode = item['laterality']    \n",
    "        if lcode and not lcode.isspace():\n",
    "            file = item['filename']\n",
    "            shutil.copyfile(os.path.join(IMAGEDIR,file), os.path.join(L2DIR,lcode,file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL：将照片镜像翻转，扩增数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image # install pillow for Python 3.X\n",
    "\n",
    "IMAGEDIR = 'fundus_image_dataset/images/'\n",
    "\n",
    "for root, dirs, files in os.walk(IMAGEDIR):\n",
    "        for f in files:\n",
    "            if f.endswith('.jpg'):\n",
    "                im = Image.open(os.path.join(root, f)).transpose(Image.FLIP_LEFT_RIGHT)                \n",
    "                im.save(os.path.join(root, f.replace('.jpg','_FLIP.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确保所有图片为RGB模式，不是RGBA模式  \n",
    "将RGBA模式的PNG文件转换为JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n",
      "471\n"
     ]
    }
   ],
   "source": [
    "print (len(l))\n",
    "to_del = []\n",
    "to_replace = []\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "target = 'fundus_image_dataset/images/'\n",
    "for root, dirs, files in os.walk(target):\n",
    "        for file in files:\n",
    "            if( not file.endswith('.db')):\n",
    "                if (utils.search_file(root, file) is not None):\n",
    "                    mode = utils.get_img_mode(os.path.join(root, file))\n",
    "                    if mode is None:\n",
    "                        utils.remove_image_in_list(l,file)\n",
    "                        to_del.append(file)\n",
    "                    elif mode == 'RGBA' and file.endswith('png'): #there are also RGB mode png files!\n",
    "                        jf = utils.convert_rgba_to_rgb(file, root)\n",
    "                        if(jf is not None):\n",
    "                            utils.replace_image_in_list(l, file, file.replace('.png','.jpg'))\n",
    "                            to_replace.append(file)\n",
    "                else:\n",
    "                    print(file,' Not Found.')\n",
    "                    \n",
    "print (len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次确认l中无无效记录\n",
    "\n",
    "import imageio\n",
    "\n",
    "for idx, item in enumerate(l):    \n",
    "    file = item['filename']\n",
    "    mode = utils.get_img_mode(os.path.join(target, file))    \n",
    "    if mode != 'RGB': \n",
    "        print(mode, file)\n",
    "    a = imageio.imread(os.path.join(target, file))\n",
    "    if (a.shape[2]!=3):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Process:  942\n",
      "After Process:  942\n"
     ]
    }
   ],
   "source": [
    "# 处理非JPG文件\n",
    "\n",
    "print('Before Process: ', len(l))\n",
    "\n",
    "nl = []\n",
    "\n",
    "for idx, item in enumerate(l):    \n",
    "    file = item['filename']\n",
    "    if file in to_replace #\n",
    "    # if file.endswith('.png'):\n",
    "        item['filename'] = file.replace('.png', '.jpg')\n",
    "    # if (file.endswith('.jpg') or file.endswith('.jpeg')):\n",
    "    nl.append(item)\n",
    "        \n",
    "l= nl\n",
    "print('After Process: ', len(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拆分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "n = len(l)\n",
    "indices = list(range(n)) # In Python 3.x. range() returns a iterator so you need to convert it to a list\n",
    "shuffle(indices)\n",
    "\n",
    "#l= np.array(l) # don't convert to array, otherwise the csv format will be incorrect\n",
    "\n",
    "all_set = [l[i] for i in indices]\n",
    "df = pd.DataFrame(all_set)\n",
    "df.to_csv('fundus_image_dataset/all_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get unique files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique image files:  469\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all = pd.read_csv('fundus_image_dataset/all_labels.csv')\n",
    "unique_files = list(set(all['filename'].values))\n",
    "print('unique image files: ', len(unique_files))\n",
    "\n",
    "import random\n",
    "test_files = random.choices(unique_files, k = 50)\n",
    "\n",
    "test_set = all.loc[all['filename'].isin(test_files)].copy().sort_values(by=['filename']).reset_index(drop=True)\n",
    "train_set = all.loc[all['filename'].isin(test_files) == False].copy().sort_values(by=['filename']).reset_index(drop=True)\n",
    "\n",
    "df = pd.DataFrame(train_set)\n",
    "df.to_csv('fundus_image_dataset/train_labels.csv')\n",
    "\n",
    "df = pd.DataFrame(test_set)\n",
    "df.to_csv('fundus_image_dataset/test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to 'fundus_image_dataset'\n",
    "\n",
    "> python generate_tfrecord.py --csv_input=train_labels.csv  --output_path=train.record  \n",
    "> python generate_tfrecord.py --csv_input=test_labels.csv  --output_path=test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 训练\n",
    "\n",
    "Add protoc.exe to PATH\n",
    "\n",
    "pip install tf-slim  \n",
    "cd tf_ssd  \n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../src/odn/tf_ssd/training'\n",
    "import os\n",
    "import shutil\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "\n",
    "os.makedirs(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cmd > cd to '/odn/tf_ssd' > run:\n",
    "\n",
    "> python train.py --logtostderr --train_dir=training --pipeline_config_path=ssd_mobilenet_v1_fundus.config\n",
    "\n",
    "[Encountered Error] tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape mismatch in tuple component 14. Expected [1,?,?,3], got [1,374,197,4]  \n",
    "[Solution] Use JPEGs only. It seems in creating TFRecords, only JPEG images are supported and nowhere in the documentation this is indicated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# Start Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD (Single Shot Detector)\n",
    "\n",
    "SSD attains a better balance between swiftness and precision. SSD runs a convolutional network on input image only one time and computes a feature map. Now, we run a small 3×3 sized convolutional kernel on this feature map to foresee the bounding boxes and categorization probability.\n",
    "\n",
    "SSD also uses anchor boxes at a variety of aspect ratio comparable to Faster-RCNN and learns the off-set to a certain extent than learning the box. In order to hold the scale, SSD predicts bounding boxes after multiple convolutional layers. Since every convolutional layer functions at a diverse scale, it is able to detect objects of a mixture of scales.\n",
    "\n",
    "# COCO\n",
    "\n",
    "COCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features:\n",
    "\n",
    "\n",
    "Model name \tSpeed (ms) \tCOCO mAP \tOutputs  \n",
    "ssd_mobilenet_v1_coco \t30 \t21 \tBoxes\n",
    "\n",
    "IoU (intersect over union) is a measure of the overlap between bboxes.   \n",
    "Correct if IoU > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard to check the training process\n",
    "\n",
    "> cd training  \n",
    "> tensorboard --logdir=.\n",
    "\n",
    "Should see the loss line drops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning: this TensorFlow binary was not compiled to use: AVX AVX2\n",
    "\n",
    "Advanced Vector Extensions (AVX) are extensions to the x86 instruction set architecture for microprocessors from Intel and AMD proposed. \n",
    "In particular, AVX introduces fused multiply-accumulate (FMA) operations, which speed up linear algebra computation, namely dot-product, matrix multiply, convolution, etc. Almost every machine-learning training involves a great deal of these operations, hence will be faster on a CPU that supports AVX and FMA (up to 300%).  \n",
    "\n",
    "Recommendation: Ignore the warning or use GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export ckpt to graph\n",
    "\n",
    "> python export_inference_graph.py --input_type image_tensor --pipeline_config_path ssd_mobilenet_v1_fundus.config --trained_checkpoint_prefix training/model.ckpt-28379 --output_directory ./export  \n",
    "\n",
    "After this step, a \"frozen_inference_graph.pb\" file is generated.\n",
    "\n",
    "[Encountered Error] ValueError: Protocol message RewriterConfig has no \"layout_optimizer\" field.  \n",
    "[Solution] Change \"layout_optimizer\" to \"optimize_tensor_layout\" in Line 72 of exporter.py  \n",
    "Or revise \"rewrite_options = rewriter_config_pb2.RewriterConfig(\n",
    "             layout_optimizer=rewriter_config_pb2.RewriterConfig.ON)\"  \n",
    "to \"rewrite_options = rewriter_config_pb2.RewriterConfig()\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue training (Optional)\n",
    "\n",
    "Revise ssd_mobilenet_v1_fundus.config: \n",
    "> fine_tune_checkpoint: \"../tf/export/model.ckpt\"\n",
    "\n",
    "Training: \n",
    "> python train.py --logtostderr --train_dir=training --pipeline_config_path=ssd_mobilenet_v1_fundus.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection Using the Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = 'tf/fundus_label_map.pbtxt'\n",
    "NUM_CLASSES = 2\n",
    "PATH_TO_CKPT = 'tf/export/frozen_inference_graph.pb' #'ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb'\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.4.0'):\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL: Copy the image folder and Resize all images to 480x360. For thumbnails, use 80x60"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%run bulk_resize_fundus_image.py\n",
    "\n",
    "# resize all images to 80x60\n",
    "bulk_resize_fundus_image('H:/ROP_201707/C3R/Integrated/Disease/', 'H:/ROP_201707/C3R/Integrated/DiseaseS/', w = 80, h = 60)\n",
    "bulk_resize_fundus_image('H:/ROP_201707/C3R/Integrated/NotDisease/', 'H:/ROP_201707/C3R/Integrated/NotDiseaseS/', w = 80, h = 60)\n",
    "bulk_resize_fundus_image('H:/ROP_201707/C3R/Integrated/Unqualified/', 'H:/ROP_201707/C3R/Integrated/UnqualifiedS/', w = 80, h = 60)\n",
    "bulk_resize_fundus_image('H:/DL_Paper/material/DataSet/C3/TestSet/Disease/', 'H:/DL_Paper/material/DataSet/C3/TestSet/DiseaseS/', w = 80, h = 60)\n",
    "bulk_resize_fundus_image('H:/DL_Paper/material/DataSet/C3/TestSet/NotDisease/', 'H:/DL_Paper/material/DataSet/C3/TestSet/NotDiseaseS/', w = 80, h = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test all the images\n",
    "\n",
    "import os\n",
    "folder = 'fundus_image_dataset/images/'\n",
    "\n",
    "FILES=[]\n",
    "for f in os.listdir(folder):\n",
    "    if os.path.isfile(folder + f) and (f.endswith('.jpg')):\n",
    "        FILES.append(folder + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./fundus_image_dataset/images/0ba2c875efc78380549d507a1df707ac.jpg',\n",
       " './fundus_image_dataset/images/40b066b77d6de95125f99d943d8cc8d3.jpg',\n",
       " './fundus_image_dataset/images/39edcff6f000a23b13dda921114eb548.jpg',\n",
       " './fundus_image_dataset/images/0c5de1b595b90a3f29f5951ce0bb0da1.jpg',\n",
       " './fundus_image_dataset/images/7b0f11ff79c96e2bc18eb77e814f53a0.jpg',\n",
       " './fundus_image_dataset/images/69c736878886c89aad7f5a1cfc9b2334.jpg',\n",
       " './fundus_image_dataset/images/9a51544acea83c8e31e6164023a40370.jpg',\n",
       " './fundus_image_dataset/images/88d8c4df420c01ce603eef1e06d4060a.jpg',\n",
       " './fundus_image_dataset/images/851a5c87068541da0effee686227f5a5.jpg',\n",
       " './fundus_image_dataset/images/3223b533d0d759fb6591cc663a96a14b.jpg',\n",
       " './fundus_image_dataset/images/881219015f3f7779c1bbc8b9de9f9b22.jpg',\n",
       " './fundus_image_dataset/images/12a624d5584d9535e73550e19990e03e.jpg',\n",
       " './fundus_image_dataset/images/5b73b3fd60cd2ae8972675be31b31db0.jpg',\n",
       " './fundus_image_dataset/images/1d0cbae1747d4e229c9f40e62d8b1a58.jpg',\n",
       " './fundus_image_dataset/images/160930bbc89eccc7b8e06a6706324c40.jpg',\n",
       " './fundus_image_dataset/images/0519cd0f02078c263f8be17e372ff017.jpg',\n",
       " './fundus_image_dataset/images/08664f44d41bea488531217d17818f49.jpg',\n",
       " './fundus_image_dataset/images/2c8a55b2caa7f83c5f2a39f881c21cdb.jpg',\n",
       " './fundus_image_dataset/images/315f6bb5a5525376023bfb4ff13a1bdf.jpg',\n",
       " './fundus_image_dataset/images/7c47417b15c96c5184ff960f1ad8ffdb.jpg',\n",
       " './fundus_image_dataset/images/5e7e38c67192a06fdabf8015a6690136.jpg',\n",
       " './fundus_image_dataset/images/53960294fb1f9b52a8fdb27d19c18809.jpg',\n",
       " './fundus_image_dataset/images/f75590286c066f25bea1facf8d7eae66.jpg',\n",
       " './fundus_image_dataset/images/34f683206d98d5abaf2ff2b19155f14f.jpg',\n",
       " './fundus_image_dataset/images/87bd194938095031c74b9a33f4b4fa2a.jpg',\n",
       " './fundus_image_dataset/images/c6be5d36d2131cba7e33d7e45f3c6e0c.jpg',\n",
       " './fundus_image_dataset/images/1f438ea0dd88dd62840a7c8a673cd535.jpg',\n",
       " './fundus_image_dataset/images/26bc51118542a2d19e4323062765b8e8.jpg',\n",
       " './fundus_image_dataset/images/9398ab85538ddcf741c5a2b3d1547151.jpg',\n",
       " './fundus_image_dataset/images/6a25a1c711a2e43486661bc9359a471c.jpg',\n",
       " './fundus_image_dataset/images/0d2449ab4bfb37567fe78f0fb8610ded.jpg',\n",
       " './fundus_image_dataset/images/0f82c9693c24fdc2cae577836654f7de.jpg',\n",
       " './fundus_image_dataset/images/0b150b5b76d138add494bdea33d71b15.jpg',\n",
       " './fundus_image_dataset/images/4fea62e17e285eb04a3122cb410c443e.jpg',\n",
       " './fundus_image_dataset/images/298c171686d6883c33882890aedbf69d.jpg',\n",
       " './fundus_image_dataset/images/5c01483b5e1fede3149405eb45585f43.jpg',\n",
       " './fundus_image_dataset/images/231ea3b6b1a3a1ce3dcd5f439933d17a.jpg',\n",
       " './fundus_image_dataset/images/e30cb045e04b50ad0c52e9f0423ebdd6.jpg',\n",
       " './fundus_image_dataset/images/07bdd141e106217be44d11e0716af6f0.jpg',\n",
       " './fundus_image_dataset/images/6da6a21f02323ee576436590c8419bcf.jpg',\n",
       " './fundus_image_dataset/images/d78acd2769c339face89e5c7aa03256f.jpg',\n",
       " './fundus_image_dataset/images/3bdb93db908c1c6fc5e38178b9d10095.jpg',\n",
       " './fundus_image_dataset/images/3f27e117d9a587a99ed763b97ce315eb.jpg',\n",
       " './fundus_image_dataset/images/75a7d54572dd8da4aa3ef91448e2bbb4.jpg',\n",
       " './fundus_image_dataset/images/9d03866708914389388ab5180664b33f.jpg',\n",
       " './fundus_image_dataset/images/dd53065b0c645514829687579bc03c78.jpg',\n",
       " './fundus_image_dataset/images/0233bf5091c42110f367bcba2e0ed80c.jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test only the test set\n",
    "\n",
    "import pandas as pd\n",
    "test_set = pd.read_csv('./keras-frcnn/test.txt', header=None)\n",
    "FILES = list(set(test_set[0].values))\n",
    "FILES = list(map(lambda x: x[1:], FILES)) # change path ../ to ./\n",
    "FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "算法改进：\n",
    "## Rule 1\n",
    "1.  判定macula面积大小，过大不考虑\n",
    "2.  判定macula与OpticDisk的距离，距离过大过小不考虑  \n",
    "\n",
    "## Rule2 \n",
    "1.\t若同时检测出OpticDisk和Macula结构，若Macula在OpticDisk左侧，则判定为OpticDiskOD；若Maclua在OpticDisk右侧，则判定为OpticDiskOS\n",
    "2.\t若检测出OpticDisk在左方边界2倍OpticDisk直径之内的范围，判定为OpticDiskOS；若检测出OpticDisk在右方边界2倍OpticDisk直径之内的范围，判定为OpticDiskOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run batch_object_detection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:06<00:00, 10.88it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_object_detection(detection_graph, category_index, FILES, 'fundus_image_dataset/ssd', 'tf/testlog20101002.txt', new_img_width = 300, fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: use tf-lite to deploy  \n",
    "\n",
    "\n",
    "\n",
    "MASK RCNN for ridge. Annotation tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Warning]  \n",
    "Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:528: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
    "  max_open_warning, RuntimeWarning)\n",
    "  \n",
    "[Solution]  \n",
    "plt.close(fig) will remove a specific figure instance from the pylab state machine (plt._pylab_helpers.Gcf) and allow it to be garbage collected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
